{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 1000000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"opus100\", \"en-zh\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'translation': {'en': 'Sixty-first session', 'zh': '第六十一届会议'}}\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "\n",
    "class T5Embedding(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math \n",
    "\n",
    "class PositionalEncoding(nn.Module): \n",
    "    def __init__(self, d_model, max_len=5000): \n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float()*(-math.log(10000.) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "    \n",
    "    def forward(self, x): \n",
    "        seq_len = x.size(1)\n",
    "        return x + self.pe[:, :seq_len].to(x.device)\n",
    "\n",
    "\n",
    "pe = PositionalEncoding(512)\n",
    "x = torch.randn(size=(2,5,512))\n",
    "# print(x[1,0,:])\n",
    "\n",
    "[para.numel() for para in pe.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 旋转位置编码\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "class RotaryEmbedding(nn.Module): \n",
    "    # 旋转位置编码实现\n",
    "    def __init__(self, dim: int, max_position: int = 10000): \n",
    "        super().__init__()\n",
    "        assert dim % 2 == 0, \"dim必须是偶数\"\n",
    "        self.dim = dim\n",
    "        self.max_position = max_position\n",
    "        \n",
    "        # 预计算频率\n",
    "        inv_freq = 1.0 / (10000 ** (torch.arange(0, dim, 2).float() / dim))\n",
    "        self.register_buffer(\"inv_freq\", inv_freq)\n",
    "        \n",
    "        # 预计算所有位置的cos和sin\n",
    "        self._precompute_embeddings()\n",
    "    \n",
    "    def _precompute_embeddings(self):\n",
    "        \"\"\"预计算最大长度的cos和sin\"\"\"\n",
    "        positions = torch.arange(self.max_position, dtype=torch.float)\n",
    "        freqs = positions[:, None] * self.inv_freq[None, :]  # (max_position, dim/2)\n",
    "        cos = torch.cos(freqs)\n",
    "        sin = torch.sin(freqs)\n",
    "        self.register_buffer(\"cos_cached\", cos, persistent=False)  # (max_position, dim/2)\n",
    "        self.register_buffer(\"sin_cached\", sin, persistent=False)\n",
    "    \n",
    "    def forward(self, seq_len: int, device: torch.device) -> tuple:\n",
    "        \"\"\"\n",
    "        在训练端，我们固定最大尺寸输入是ok的。因为我们为了训练，对传进来的序列长度对齐的。设定了最大长度规则，截断规则。\n",
    "        但是在预测段，最大固定尺寸max_position需要设置的大一些。大部分任务是单样本推理。此时，如果max_position设置过小，可能对生成结果有影响\n",
    "        我们，一般可以和对话最大字符度相同。或者略低。\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"根据序列长度返回对应的cos和sin\"\"\"\n",
    "        assert seq_len <= self.max_position, f\"seq_len ({seq_len}) 超过 max_position ({self.max_position})\"\n",
    "        \n",
    "        # 从缓存中截取需要的部分\n",
    "        cos = self.cos_cached[:seq_len].to(device)\n",
    "        sin = self.sin_cached[:seq_len].to(device)\n",
    "        return cos, sin\n",
    "    \n",
    "# 在单向or双向自注意力时可以这样操作。因为q，k同维度，当涉及交叉注意力时，此时就不能这么操作了，在训练时，由于我们设置max_length都一样长，可能并无感知。\n",
    "# 但在训练时，编码端长度和解码端长度大多数情况下是未对齐的，此时就会报错。 \n",
    "def apply_rotary_emb(q: torch.Tensor, k: torch.Tensor, cos: torch.Tensor, sin: torch.Tensor) -> tuple:\n",
    "    \"\"\"应用旋转位置编码\"\"\"\n",
    "    # 调整 cos 和 sin 的形状以匹配 q 和 k\n",
    "    # cos, sin 原本shape是 (seq_len, d_k//2)\n",
    "    cos = cos.unsqueeze(-2)  # 扩展维度为(seq_len, 1, d_k//2) 最后通过广播机制维度扩展(batch_size, seq_len, num_heads, d_k//2)\n",
    "    sin = sin.unsqueeze(-2)  # 扩展维度为(seq_len, 1, d_k//2) 最后通过广播机制维度扩展(batch_size, seq_len, num_heads, d_k//2)\n",
    "    q_ = q.float()\n",
    "    k_ = k.float()\n",
    "    trunc = q_.shape[-1] // 2\n",
    "    \n",
    "    q_rot = torch.cat([q_[..., :trunc] * cos - q_[..., trunc:] * sin,\n",
    "                      q_[..., :trunc] * sin + q_[..., trunc:] * cos], dim=-1)\n",
    "    k_rot = torch.cat([k_[..., :trunc] * cos - k_[..., trunc:] * sin,\n",
    "                      k_[..., :trunc] * sin + k_[..., trunc:] * cos], dim=-1)\n",
    "    return q_rot.type_as(q), k_rot.type_as(k)\n",
    "\n",
    "# 在交叉注意力时，由于q，k的长度不一致。如果我们用常规的ROPE就不行，维度没有对齐。因此，在交叉注意力计算时，我们需要计算各自的ROPE值\n",
    "def apply_rotary_emb_single(x: torch.Tensor, cos: torch.Tensor, sin: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"应用旋转位置编码到单个张量\"\"\"\n",
    "    cos = cos.unsqueeze(-2)  # 扩展维度为(seq_len, 1, d_k//2) 最后通过广播机制维度扩展(batch_size, seq_len, num_heads, d_k//2)\n",
    "    sin = sin.unsqueeze(-2)  # 扩展维度为(seq_len, 1, d_k//2) 最后通过广播机制维度扩展(batch_size, seq_len, num_heads, d_k//2)\n",
    "    x_ = x.float()\n",
    "    trunc = x_.shape[-1] // 2\n",
    "    x_rot = torch.cat([\n",
    "        x_[..., :trunc] * cos - x_[..., trunc:] * sin,\n",
    "        x_[..., :trunc] * sin + x_[..., trunc:] * cos\n",
    "    ], dim=-1)\n",
    "    return x_rot.type_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flash_attn import flash_attn_func\n",
    "\n",
    "class MultiHeadAttention(nn.Module): \n",
    "    def __init__(self, d_model, num_heads, max_position=10000, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model必须被num_heads整除\"\n",
    "        self.dropout = dropout\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_model // num_heads\n",
    "        self.q_linear = nn.Linear(d_model, d_model)    \n",
    "        self.k_linear = nn.Linear(d_model, d_model)    \n",
    "        self.v_linear = nn.Linear(d_model, d_model)    \n",
    "        self.out_linear = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        # 初始化旋转位置编码\n",
    "        self.rotary_emb = RotaryEmbedding(self.d_k, max_position) \n",
    "        \n",
    "    # 始终应用掩码（如果 mask 为 None，则传入全 1 掩码） 这样设计的目的是，方便模型后续输出为onnx格式，该格式不建议if for等语句\n",
    "    # src_mask shape可以是：(batch_size, 1, 1, seq_len)， 通过广播同步维度到 (batch_size, num_heads, seq_len, seq_len)\n",
    "    # tgt_mask shape可以是：(batch_size, 1, seq_len, seq_len)， 通过广播同步维度到 (batch_size, num_heads, seq_len, seq_len)\n",
    "    def forward(self, q, k, v, mask=None, use_flash_attn=False): \n",
    "        batch_size = q.size(0)\n",
    "        q_seq_len = q.size(1)  # q 的序列长度\n",
    "        k_seq_len = k.size(1)  # k 的序列长度\n",
    "        \n",
    "        # 线性变换并分割为多头\n",
    "        q = self.q_linear(q).view(batch_size, -1, self.num_heads, self.d_k)\n",
    "        k = self.k_linear(k).view(batch_size, -1, self.num_heads, self.d_k)\n",
    "        v = self.v_linear(v).view(batch_size, -1, self.num_heads, self.d_k)\n",
    "        \n",
    "        # 为 q 和 k 分别生成旋转位置编码\n",
    "        cos_q, sin_q = self.rotary_emb(q_seq_len, q.device)\n",
    "        cos_k, sin_k = self.rotary_emb(k_seq_len, k.device)\n",
    "\n",
    "        # 分别应用旋转位置编码\n",
    "        q = apply_rotary_emb_single(q, cos_q, sin_q)\n",
    "        k = apply_rotary_emb_single(k, cos_k, sin_k)\n",
    "\n",
    "\n",
    "        # 单双向自注意力时可以使用，交叉注意力时，需要分别计算。\n",
    "        # q, k = apply_rotary_emb(q, k, cos, sin)\n",
    "        \n",
    "        if use_flash_attn:\n",
    "            # multi-attention 训练模式\n",
    "            # multi-attention 要求输入格式为 (batch_size, num_heads, seq_len, d_k)\n",
    "            q, k, v = q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2)\n",
    "            scores = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(self.d_k)\n",
    "            \n",
    "            # -1e9在半精度等训练时，会溢出，这里选择-1e4\n",
    "            # scores = scores.masked_fill(mask==0, -1e9)\n",
    "            scores = scores.masked_fill(mask==0, -1e4)\n",
    "            attention = torch.softmax(scores, dim=-1)\n",
    "            output = torch.matmul(attention, v)\n",
    "            output = output.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
    "        else: \n",
    "            # flash-attention 推理模式\n",
    "            # Flash Attention 要求输入格式为 (batch_size, seq_len, num_heads, d_k)\n",
    "            output = flash_attn_func(\n",
    "                q, k, v,\n",
    "                dropout_p=0, # 推理时，不使用dropout\n",
    "                softmax_scale=1. / math.sqrt(self.d_k), # 缩放因子\n",
    "                causal=True, # 内置生成因果掩码，但是他不对ipaddng等处理。所以，在训练端不合适\n",
    "                # 在推理端生成任务时，由于没有padding的影响。解码端或gpt等使用内置掩码即可，如果是编解码，编码端还是需要传入attention_mask\n",
    "            )             \n",
    "            output = output.view(batch_size, -1, self.d_model)\n",
    "        \n",
    "        return self.out_linear(output)\n",
    "    \n",
    "\n",
    "attn = MultiHeadAttention(512, 8)\n",
    "q = torch.randn(2, 10, 512)\n",
    "\n",
    "# attn(q, q, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[262144, 512, 262144, 512, 262144, 512, 262144, 512]\n",
      "1050624\n"
     ]
    }
   ],
   "source": [
    "params = [param.numel() for param in attn.parameters()]\n",
    "print(params)\n",
    "sum = 0\n",
    "for i in params:\n",
    "    sum += i \n",
    "print(sum)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1048576, 2048, 1048576, 512]\n",
      "2099712\n"
     ]
    }
   ],
   "source": [
    "class FeedForward(nn.Module): \n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "        \n",
    "    def forward(self, x): \n",
    "        return self.linear2(torch.relu(self.linear1(x)))\n",
    "    \n",
    "ffn = FeedForward(512, 2048)\n",
    "param = [para.numel() for para in ffn.parameters()]\n",
    "print(param)\n",
    "sum = 0 \n",
    "for i in param:\n",
    "    sum += i\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[262144, 512, 262144, 512, 262144, 512, 262144, 512, 1048576, 2048, 1048576, 512, 512, 512, 512, 512]\n",
      "3152384\n"
     ]
    }
   ],
   "source": [
    "class EncoderLayer(nn.Module): \n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ff = FeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        x = x + self.dropout(self.self_attn(self.norm1(x), self.norm1(x), self.norm1(x), mask))\n",
    "        x = x + self.dropout(self.ff(self.norm2(x)))\n",
    "        return x \n",
    "\n",
    "encoder_block = EncoderLayer(512, 8, 2048, 0.1)\n",
    "params = [param.numel() for param in encoder_block.parameters()]\n",
    "print(params)\n",
    "sum = 0 \n",
    "for i in params:\n",
    "    sum += i\n",
    "    \n",
    "# 参数量统计\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[262144, 512, 262144, 512, 262144, 512, 262144, 512, 262144, 512, 262144, 512, 262144, 512, 262144, 512, 1048576, 2048, 1048576, 512, 512, 512, 512, 512, 512, 512]\n",
      "4204032\n"
     ]
    }
   ],
   "source": [
    "class DecoderLayer(nn.Module): \n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ff = FeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model) \n",
    "        self.norm2 = nn.LayerNorm(d_model) \n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, enc_output, src_mask=None, tgt_mask=None, use_flash_attn=False): \n",
    "         x = x + self.dropout(self.self_attn(self.norm1(x), self.norm1(x), self.norm1(x), tgt_mask, use_flash_attn))\n",
    "         x = x + self.dropout(self.cross_attn(self.norm2(x), enc_output, enc_output, src_mask, use_flash_attn))\n",
    "         x = x + self.dropout(self.ff(self.norm3(x)))\n",
    "         return x \n",
    "     \n",
    "decoder_block = DecoderLayer(512, 8, 2048)\n",
    "\n",
    "params = [para.numel() for para in decoder_block.parameters()]\n",
    "print(params)\n",
    "sum = 0\n",
    "for i in params:\n",
    "    sum += i\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding.embedding.weight ==> 参数量：15360000\n",
      "encoder_layers.0.self_attn.q_linear.weight ==> 参数量：589824\n",
      "encoder_layers.0.self_attn.q_linear.bias ==> 参数量：768\n",
      "encoder_layers.0.self_attn.k_linear.weight ==> 参数量：589824\n",
      "encoder_layers.0.self_attn.k_linear.bias ==> 参数量：768\n",
      "encoder_layers.0.self_attn.v_linear.weight ==> 参数量：589824\n",
      "encoder_layers.0.self_attn.v_linear.bias ==> 参数量：768\n",
      "encoder_layers.0.self_attn.out_linear.weight ==> 参数量：589824\n",
      "encoder_layers.0.self_attn.out_linear.bias ==> 参数量：768\n",
      "encoder_layers.0.ff.linear1.weight ==> 参数量：1572864\n",
      "encoder_layers.0.ff.linear1.bias ==> 参数量：2048\n",
      "encoder_layers.0.ff.linear2.weight ==> 参数量：1572864\n",
      "encoder_layers.0.ff.linear2.bias ==> 参数量：768\n",
      "encoder_layers.0.norm1.weight ==> 参数量：768\n",
      "encoder_layers.0.norm1.bias ==> 参数量：768\n",
      "encoder_layers.0.norm2.weight ==> 参数量：768\n",
      "encoder_layers.0.norm2.bias ==> 参数量：768\n",
      "encoder_layers.1.self_attn.q_linear.weight ==> 参数量：589824\n",
      "encoder_layers.1.self_attn.q_linear.bias ==> 参数量：768\n",
      "encoder_layers.1.self_attn.k_linear.weight ==> 参数量：589824\n",
      "encoder_layers.1.self_attn.k_linear.bias ==> 参数量：768\n",
      "encoder_layers.1.self_attn.v_linear.weight ==> 参数量：589824\n",
      "encoder_layers.1.self_attn.v_linear.bias ==> 参数量：768\n",
      "encoder_layers.1.self_attn.out_linear.weight ==> 参数量：589824\n",
      "encoder_layers.1.self_attn.out_linear.bias ==> 参数量：768\n",
      "encoder_layers.1.ff.linear1.weight ==> 参数量：1572864\n",
      "encoder_layers.1.ff.linear1.bias ==> 参数量：2048\n",
      "encoder_layers.1.ff.linear2.weight ==> 参数量：1572864\n",
      "encoder_layers.1.ff.linear2.bias ==> 参数量：768\n",
      "encoder_layers.1.norm1.weight ==> 参数量：768\n",
      "encoder_layers.1.norm1.bias ==> 参数量：768\n",
      "encoder_layers.1.norm2.weight ==> 参数量：768\n",
      "encoder_layers.1.norm2.bias ==> 参数量：768\n",
      "encoder_layers.2.self_attn.q_linear.weight ==> 参数量：589824\n",
      "encoder_layers.2.self_attn.q_linear.bias ==> 参数量：768\n",
      "encoder_layers.2.self_attn.k_linear.weight ==> 参数量：589824\n",
      "encoder_layers.2.self_attn.k_linear.bias ==> 参数量：768\n",
      "encoder_layers.2.self_attn.v_linear.weight ==> 参数量：589824\n",
      "encoder_layers.2.self_attn.v_linear.bias ==> 参数量：768\n",
      "encoder_layers.2.self_attn.out_linear.weight ==> 参数量：589824\n",
      "encoder_layers.2.self_attn.out_linear.bias ==> 参数量：768\n",
      "encoder_layers.2.ff.linear1.weight ==> 参数量：1572864\n",
      "encoder_layers.2.ff.linear1.bias ==> 参数量：2048\n",
      "encoder_layers.2.ff.linear2.weight ==> 参数量：1572864\n",
      "encoder_layers.2.ff.linear2.bias ==> 参数量：768\n",
      "encoder_layers.2.norm1.weight ==> 参数量：768\n",
      "encoder_layers.2.norm1.bias ==> 参数量：768\n",
      "encoder_layers.2.norm2.weight ==> 参数量：768\n",
      "encoder_layers.2.norm2.bias ==> 参数量：768\n",
      "encoder_layers.3.self_attn.q_linear.weight ==> 参数量：589824\n",
      "encoder_layers.3.self_attn.q_linear.bias ==> 参数量：768\n",
      "encoder_layers.3.self_attn.k_linear.weight ==> 参数量：589824\n",
      "encoder_layers.3.self_attn.k_linear.bias ==> 参数量：768\n",
      "encoder_layers.3.self_attn.v_linear.weight ==> 参数量：589824\n",
      "encoder_layers.3.self_attn.v_linear.bias ==> 参数量：768\n",
      "encoder_layers.3.self_attn.out_linear.weight ==> 参数量：589824\n",
      "encoder_layers.3.self_attn.out_linear.bias ==> 参数量：768\n",
      "encoder_layers.3.ff.linear1.weight ==> 参数量：1572864\n",
      "encoder_layers.3.ff.linear1.bias ==> 参数量：2048\n",
      "encoder_layers.3.ff.linear2.weight ==> 参数量：1572864\n",
      "encoder_layers.3.ff.linear2.bias ==> 参数量：768\n",
      "encoder_layers.3.norm1.weight ==> 参数量：768\n",
      "encoder_layers.3.norm1.bias ==> 参数量：768\n",
      "encoder_layers.3.norm2.weight ==> 参数量：768\n",
      "encoder_layers.3.norm2.bias ==> 参数量：768\n",
      "encoder_layers.4.self_attn.q_linear.weight ==> 参数量：589824\n",
      "encoder_layers.4.self_attn.q_linear.bias ==> 参数量：768\n",
      "encoder_layers.4.self_attn.k_linear.weight ==> 参数量：589824\n",
      "encoder_layers.4.self_attn.k_linear.bias ==> 参数量：768\n",
      "encoder_layers.4.self_attn.v_linear.weight ==> 参数量：589824\n",
      "encoder_layers.4.self_attn.v_linear.bias ==> 参数量：768\n",
      "encoder_layers.4.self_attn.out_linear.weight ==> 参数量：589824\n",
      "encoder_layers.4.self_attn.out_linear.bias ==> 参数量：768\n",
      "encoder_layers.4.ff.linear1.weight ==> 参数量：1572864\n",
      "encoder_layers.4.ff.linear1.bias ==> 参数量：2048\n",
      "encoder_layers.4.ff.linear2.weight ==> 参数量：1572864\n",
      "encoder_layers.4.ff.linear2.bias ==> 参数量：768\n",
      "encoder_layers.4.norm1.weight ==> 参数量：768\n",
      "encoder_layers.4.norm1.bias ==> 参数量：768\n",
      "encoder_layers.4.norm2.weight ==> 参数量：768\n",
      "encoder_layers.4.norm2.bias ==> 参数量：768\n",
      "encoder_layers.5.self_attn.q_linear.weight ==> 参数量：589824\n",
      "encoder_layers.5.self_attn.q_linear.bias ==> 参数量：768\n",
      "encoder_layers.5.self_attn.k_linear.weight ==> 参数量：589824\n",
      "encoder_layers.5.self_attn.k_linear.bias ==> 参数量：768\n",
      "encoder_layers.5.self_attn.v_linear.weight ==> 参数量：589824\n",
      "encoder_layers.5.self_attn.v_linear.bias ==> 参数量：768\n",
      "encoder_layers.5.self_attn.out_linear.weight ==> 参数量：589824\n",
      "encoder_layers.5.self_attn.out_linear.bias ==> 参数量：768\n",
      "encoder_layers.5.ff.linear1.weight ==> 参数量：1572864\n",
      "encoder_layers.5.ff.linear1.bias ==> 参数量：2048\n",
      "encoder_layers.5.ff.linear2.weight ==> 参数量：1572864\n",
      "encoder_layers.5.ff.linear2.bias ==> 参数量：768\n",
      "encoder_layers.5.norm1.weight ==> 参数量：768\n",
      "encoder_layers.5.norm1.bias ==> 参数量：768\n",
      "encoder_layers.5.norm2.weight ==> 参数量：768\n",
      "encoder_layers.5.norm2.bias ==> 参数量：768\n",
      "decoder_layers.0.self_attn.q_linear.weight ==> 参数量：589824\n",
      "decoder_layers.0.self_attn.q_linear.bias ==> 参数量：768\n",
      "decoder_layers.0.self_attn.k_linear.weight ==> 参数量：589824\n",
      "decoder_layers.0.self_attn.k_linear.bias ==> 参数量：768\n",
      "decoder_layers.0.self_attn.v_linear.weight ==> 参数量：589824\n",
      "decoder_layers.0.self_attn.v_linear.bias ==> 参数量：768\n",
      "decoder_layers.0.self_attn.out_linear.weight ==> 参数量：589824\n",
      "decoder_layers.0.self_attn.out_linear.bias ==> 参数量：768\n",
      "decoder_layers.0.cross_attn.q_linear.weight ==> 参数量：589824\n",
      "decoder_layers.0.cross_attn.q_linear.bias ==> 参数量：768\n",
      "decoder_layers.0.cross_attn.k_linear.weight ==> 参数量：589824\n",
      "decoder_layers.0.cross_attn.k_linear.bias ==> 参数量：768\n",
      "decoder_layers.0.cross_attn.v_linear.weight ==> 参数量：589824\n",
      "decoder_layers.0.cross_attn.v_linear.bias ==> 参数量：768\n",
      "decoder_layers.0.cross_attn.out_linear.weight ==> 参数量：589824\n",
      "decoder_layers.0.cross_attn.out_linear.bias ==> 参数量：768\n",
      "decoder_layers.0.ff.linear1.weight ==> 参数量：1572864\n",
      "decoder_layers.0.ff.linear1.bias ==> 参数量：2048\n",
      "decoder_layers.0.ff.linear2.weight ==> 参数量：1572864\n",
      "decoder_layers.0.ff.linear2.bias ==> 参数量：768\n",
      "decoder_layers.0.norm1.weight ==> 参数量：768\n",
      "decoder_layers.0.norm1.bias ==> 参数量：768\n",
      "decoder_layers.0.norm2.weight ==> 参数量：768\n",
      "decoder_layers.0.norm2.bias ==> 参数量：768\n",
      "decoder_layers.0.norm3.weight ==> 参数量：768\n",
      "decoder_layers.0.norm3.bias ==> 参数量：768\n",
      "decoder_layers.1.self_attn.q_linear.weight ==> 参数量：589824\n",
      "decoder_layers.1.self_attn.q_linear.bias ==> 参数量：768\n",
      "decoder_layers.1.self_attn.k_linear.weight ==> 参数量：589824\n",
      "decoder_layers.1.self_attn.k_linear.bias ==> 参数量：768\n",
      "decoder_layers.1.self_attn.v_linear.weight ==> 参数量：589824\n",
      "decoder_layers.1.self_attn.v_linear.bias ==> 参数量：768\n",
      "decoder_layers.1.self_attn.out_linear.weight ==> 参数量：589824\n",
      "decoder_layers.1.self_attn.out_linear.bias ==> 参数量：768\n",
      "decoder_layers.1.cross_attn.q_linear.weight ==> 参数量：589824\n",
      "decoder_layers.1.cross_attn.q_linear.bias ==> 参数量：768\n",
      "decoder_layers.1.cross_attn.k_linear.weight ==> 参数量：589824\n",
      "decoder_layers.1.cross_attn.k_linear.bias ==> 参数量：768\n",
      "decoder_layers.1.cross_attn.v_linear.weight ==> 参数量：589824\n",
      "decoder_layers.1.cross_attn.v_linear.bias ==> 参数量：768\n",
      "decoder_layers.1.cross_attn.out_linear.weight ==> 参数量：589824\n",
      "decoder_layers.1.cross_attn.out_linear.bias ==> 参数量：768\n",
      "decoder_layers.1.ff.linear1.weight ==> 参数量：1572864\n",
      "decoder_layers.1.ff.linear1.bias ==> 参数量：2048\n",
      "decoder_layers.1.ff.linear2.weight ==> 参数量：1572864\n",
      "decoder_layers.1.ff.linear2.bias ==> 参数量：768\n",
      "decoder_layers.1.norm1.weight ==> 参数量：768\n",
      "decoder_layers.1.norm1.bias ==> 参数量：768\n",
      "decoder_layers.1.norm2.weight ==> 参数量：768\n",
      "decoder_layers.1.norm2.bias ==> 参数量：768\n",
      "decoder_layers.1.norm3.weight ==> 参数量：768\n",
      "decoder_layers.1.norm3.bias ==> 参数量：768\n",
      "decoder_layers.2.self_attn.q_linear.weight ==> 参数量：589824\n",
      "decoder_layers.2.self_attn.q_linear.bias ==> 参数量：768\n",
      "decoder_layers.2.self_attn.k_linear.weight ==> 参数量：589824\n",
      "decoder_layers.2.self_attn.k_linear.bias ==> 参数量：768\n",
      "decoder_layers.2.self_attn.v_linear.weight ==> 参数量：589824\n",
      "decoder_layers.2.self_attn.v_linear.bias ==> 参数量：768\n",
      "decoder_layers.2.self_attn.out_linear.weight ==> 参数量：589824\n",
      "decoder_layers.2.self_attn.out_linear.bias ==> 参数量：768\n",
      "decoder_layers.2.cross_attn.q_linear.weight ==> 参数量：589824\n",
      "decoder_layers.2.cross_attn.q_linear.bias ==> 参数量：768\n",
      "decoder_layers.2.cross_attn.k_linear.weight ==> 参数量：589824\n",
      "decoder_layers.2.cross_attn.k_linear.bias ==> 参数量：768\n",
      "decoder_layers.2.cross_attn.v_linear.weight ==> 参数量：589824\n",
      "decoder_layers.2.cross_attn.v_linear.bias ==> 参数量：768\n",
      "decoder_layers.2.cross_attn.out_linear.weight ==> 参数量：589824\n",
      "decoder_layers.2.cross_attn.out_linear.bias ==> 参数量：768\n",
      "decoder_layers.2.ff.linear1.weight ==> 参数量：1572864\n",
      "decoder_layers.2.ff.linear1.bias ==> 参数量：2048\n",
      "decoder_layers.2.ff.linear2.weight ==> 参数量：1572864\n",
      "decoder_layers.2.ff.linear2.bias ==> 参数量：768\n",
      "decoder_layers.2.norm1.weight ==> 参数量：768\n",
      "decoder_layers.2.norm1.bias ==> 参数量：768\n",
      "decoder_layers.2.norm2.weight ==> 参数量：768\n",
      "decoder_layers.2.norm2.bias ==> 参数量：768\n",
      "decoder_layers.2.norm3.weight ==> 参数量：768\n",
      "decoder_layers.2.norm3.bias ==> 参数量：768\n",
      "decoder_layers.3.self_attn.q_linear.weight ==> 参数量：589824\n",
      "decoder_layers.3.self_attn.q_linear.bias ==> 参数量：768\n",
      "decoder_layers.3.self_attn.k_linear.weight ==> 参数量：589824\n",
      "decoder_layers.3.self_attn.k_linear.bias ==> 参数量：768\n",
      "decoder_layers.3.self_attn.v_linear.weight ==> 参数量：589824\n",
      "decoder_layers.3.self_attn.v_linear.bias ==> 参数量：768\n",
      "decoder_layers.3.self_attn.out_linear.weight ==> 参数量：589824\n",
      "decoder_layers.3.self_attn.out_linear.bias ==> 参数量：768\n",
      "decoder_layers.3.cross_attn.q_linear.weight ==> 参数量：589824\n",
      "decoder_layers.3.cross_attn.q_linear.bias ==> 参数量：768\n",
      "decoder_layers.3.cross_attn.k_linear.weight ==> 参数量：589824\n",
      "decoder_layers.3.cross_attn.k_linear.bias ==> 参数量：768\n",
      "decoder_layers.3.cross_attn.v_linear.weight ==> 参数量：589824\n",
      "decoder_layers.3.cross_attn.v_linear.bias ==> 参数量：768\n",
      "decoder_layers.3.cross_attn.out_linear.weight ==> 参数量：589824\n",
      "decoder_layers.3.cross_attn.out_linear.bias ==> 参数量：768\n",
      "decoder_layers.3.ff.linear1.weight ==> 参数量：1572864\n",
      "decoder_layers.3.ff.linear1.bias ==> 参数量：2048\n",
      "decoder_layers.3.ff.linear2.weight ==> 参数量：1572864\n",
      "decoder_layers.3.ff.linear2.bias ==> 参数量：768\n",
      "decoder_layers.3.norm1.weight ==> 参数量：768\n",
      "decoder_layers.3.norm1.bias ==> 参数量：768\n",
      "decoder_layers.3.norm2.weight ==> 参数量：768\n",
      "decoder_layers.3.norm2.bias ==> 参数量：768\n",
      "decoder_layers.3.norm3.weight ==> 参数量：768\n",
      "decoder_layers.3.norm3.bias ==> 参数量：768\n",
      "decoder_layers.4.self_attn.q_linear.weight ==> 参数量：589824\n",
      "decoder_layers.4.self_attn.q_linear.bias ==> 参数量：768\n",
      "decoder_layers.4.self_attn.k_linear.weight ==> 参数量：589824\n",
      "decoder_layers.4.self_attn.k_linear.bias ==> 参数量：768\n",
      "decoder_layers.4.self_attn.v_linear.weight ==> 参数量：589824\n",
      "decoder_layers.4.self_attn.v_linear.bias ==> 参数量：768\n",
      "decoder_layers.4.self_attn.out_linear.weight ==> 参数量：589824\n",
      "decoder_layers.4.self_attn.out_linear.bias ==> 参数量：768\n",
      "decoder_layers.4.cross_attn.q_linear.weight ==> 参数量：589824\n",
      "decoder_layers.4.cross_attn.q_linear.bias ==> 参数量：768\n",
      "decoder_layers.4.cross_attn.k_linear.weight ==> 参数量：589824\n",
      "decoder_layers.4.cross_attn.k_linear.bias ==> 参数量：768\n",
      "decoder_layers.4.cross_attn.v_linear.weight ==> 参数量：589824\n",
      "decoder_layers.4.cross_attn.v_linear.bias ==> 参数量：768\n",
      "decoder_layers.4.cross_attn.out_linear.weight ==> 参数量：589824\n",
      "decoder_layers.4.cross_attn.out_linear.bias ==> 参数量：768\n",
      "decoder_layers.4.ff.linear1.weight ==> 参数量：1572864\n",
      "decoder_layers.4.ff.linear1.bias ==> 参数量：2048\n",
      "decoder_layers.4.ff.linear2.weight ==> 参数量：1572864\n",
      "decoder_layers.4.ff.linear2.bias ==> 参数量：768\n",
      "decoder_layers.4.norm1.weight ==> 参数量：768\n",
      "decoder_layers.4.norm1.bias ==> 参数量：768\n",
      "decoder_layers.4.norm2.weight ==> 参数量：768\n",
      "decoder_layers.4.norm2.bias ==> 参数量：768\n",
      "decoder_layers.4.norm3.weight ==> 参数量：768\n",
      "decoder_layers.4.norm3.bias ==> 参数量：768\n",
      "decoder_layers.5.self_attn.q_linear.weight ==> 参数量：589824\n",
      "decoder_layers.5.self_attn.q_linear.bias ==> 参数量：768\n",
      "decoder_layers.5.self_attn.k_linear.weight ==> 参数量：589824\n",
      "decoder_layers.5.self_attn.k_linear.bias ==> 参数量：768\n",
      "decoder_layers.5.self_attn.v_linear.weight ==> 参数量：589824\n",
      "decoder_layers.5.self_attn.v_linear.bias ==> 参数量：768\n",
      "decoder_layers.5.self_attn.out_linear.weight ==> 参数量：589824\n",
      "decoder_layers.5.self_attn.out_linear.bias ==> 参数量：768\n",
      "decoder_layers.5.cross_attn.q_linear.weight ==> 参数量：589824\n",
      "decoder_layers.5.cross_attn.q_linear.bias ==> 参数量：768\n",
      "decoder_layers.5.cross_attn.k_linear.weight ==> 参数量：589824\n",
      "decoder_layers.5.cross_attn.k_linear.bias ==> 参数量：768\n",
      "decoder_layers.5.cross_attn.v_linear.weight ==> 参数量：589824\n",
      "decoder_layers.5.cross_attn.v_linear.bias ==> 参数量：768\n",
      "decoder_layers.5.cross_attn.out_linear.weight ==> 参数量：589824\n",
      "decoder_layers.5.cross_attn.out_linear.bias ==> 参数量：768\n",
      "decoder_layers.5.ff.linear1.weight ==> 参数量：1572864\n",
      "decoder_layers.5.ff.linear1.bias ==> 参数量：2048\n",
      "decoder_layers.5.ff.linear2.weight ==> 参数量：1572864\n",
      "decoder_layers.5.ff.linear2.bias ==> 参数量：768\n",
      "decoder_layers.5.norm1.weight ==> 参数量：768\n",
      "decoder_layers.5.norm1.bias ==> 参数量：768\n",
      "decoder_layers.5.norm2.weight ==> 参数量：768\n",
      "decoder_layers.5.norm2.bias ==> 参数量：768\n",
      "decoder_layers.5.norm3.weight ==> 参数量：768\n",
      "decoder_layers.5.norm3.bias ==> 参数量：768\n",
      "output_layer.weight ==> 参数量：15360000\n",
      "output_layer.bias ==> 参数量：20000\n",
      "111091232\n"
     ]
    }
   ],
   "source": [
    "# 组合T5模型\n",
    "class T5Model(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, num_heads, d_ff, num_layers, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embedding = T5Embedding(vocab_size, d_model)\n",
    "        \n",
    "        # 使用了相对位置编码ROPE，这里注释掉去\n",
    "        # self.pos_encoding = PositionalEncoding(d_model)\n",
    "        \n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.output_layer = nn.Linear(d_model, vocab_size)\n",
    "    \n",
    "    def forward(self, src_input, tgt_input, src_mask=None, tgt_mask=None, use_flash_attn=False): \n",
    "        # src_emb = self.pos_encoding(self.embedding(src_input)) # 不需要经过绝对位置编码\n",
    "        # tgt_emb = self.pos_encoding(self.embedding(tgt_input)) # 不需要经过绝对位置编码\n",
    "        src_emb = self.embedding(src_input)\n",
    "        tgt_emb = self.embedding(tgt_input)\n",
    "        \n",
    "        enc_output = src_emb \n",
    "        for layer in self.encoder_layers:\n",
    "            enc_output = layer(enc_output, src_mask)\n",
    "        \n",
    "        dec_output = tgt_emb\n",
    "        for layer in self.decoder_layers:\n",
    "            dec_output = layer(dec_output, enc_output, src_mask, tgt_mask, use_flash_attn)\n",
    "        \n",
    "        return self.output_layer(dec_output)\n",
    "    \n",
    "t5 = T5Model(20000, 768, 8, 2048, 6, 0.1)\n",
    "\n",
    "sum = 0 \n",
    "\n",
    "for name,param in t5.named_parameters(): \n",
    "    print(f\"{name} ==> 参数量：{param.numel()}\")\n",
    "    sum += param.numel()\n",
    "    \n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 生成词汇表\n",
    "# from generate_tokenizer import gen_tokenizer\n",
    "\n",
    "# # 传入语料库文件， 输出tokenizer的json文件\n",
    "# src_path = \"corpus.txt\"\n",
    "# tokenizer_path = \"translation.json\"\n",
    "# gen_tokenizer(src_path, tokenizer_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad token: [PAD]\n",
      "特殊 token 映射： {'bos_token': '[BOS]', 'eos_token': '[EOS]', 'unk_token': '[UNK]', 'pad_token': '[PAD]'}\n",
      "Pad token ID: 0\n",
      "BOS token ID: 2\n",
      "BOS token ID: 2\n",
      "EOS token ID: 3\n",
      "PAD token ID: 0\n",
      "EOS token ID: 3\n"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "# 加载 tokenizer，显式设置特殊 token\n",
    "tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_file=\"translation.json\",\n",
    "    pad_token=\"[PAD]\",\n",
    "    unk_token=\"[UNK]\",\n",
    "    bos_token=\"[BOS]\",\n",
    "    eos_token=\"[EOS]\"\n",
    ")\n",
    "\n",
    "# 打印特殊 token 和映射\n",
    "print(\"Pad token:\", tokenizer.pad_token)\n",
    "print(\"特殊 token 映射：\", tokenizer.special_tokens_map)\n",
    "print(\"Pad token ID:\", tokenizer.pad_token_id)\n",
    "print(\"BOS token ID:\", tokenizer.convert_tokens_to_ids(\"[BOS]\"))\n",
    "print(\"BOS token ID:\", tokenizer.convert_tokens_to_ids(\"[BOS]\"))\n",
    "print(\"EOS token ID:\", tokenizer.convert_tokens_to_ids(\"[EOS]\"))\n",
    "print(\"PAD token ID:\", tokenizer.convert_tokens_to_ids(\"[PAD]\"))\n",
    "print(\"EOS token ID:\", tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token ID: [2, 14860, 18, 10298, 7, 13791, 9209, 9863, 9198, 3]\n",
      "分词结果： ['Hello', ',', 'world', '!', '你好', '，', '世界', '！']\n",
      "Encoded 输出: {'input_ids': tensor([[    2, 14860,    18, 10298,     7, 13791,  9209,  9863,  9198,     3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Input IDs: tensor([[    2, 14860,    18, 10298,     7, 13791,  9209,  9863,  9198,     3]])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "带特殊 token 的分词结果： ['[BOS]', 'Hello', ',', 'world', '!', '你好', '，', '世界', '！', '[EOS]']\n"
     ]
    }
   ],
   "source": [
    "# 输入文本\n",
    "text = \"Hello, world! 你好，世界！\"\n",
    "\n",
    "# 转换为 token ID\n",
    "input_ids = tokenizer.encode(text)\n",
    "print(f\"Token ID: {input_ids}\")\n",
    "\n",
    "# 查看分词后的 token\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(\"分词结果：\", tokens)\n",
    "\n",
    "encoded = tokenizer(\n",
    "    text,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512\n",
    ")\n",
    "print(\"Encoded 输出:\", encoded)\n",
    "\n",
    "# 提取 input_ids 和 attention_mask\n",
    "input_ids = encoded[\"input_ids\"]\n",
    "attention_mask = encoded[\"attention_mask\"]\n",
    "print(\"Input IDs:\", input_ids)\n",
    "print(\"Attention Mask:\", attention_mask)\n",
    "\n",
    "# 转换为 token 查看\n",
    "tokens_with_special = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "print(\"带特殊 token 的分词结果：\", tokens_with_special)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token ID:[2, 14860, 18, 10298, 7, 13791, 9209, 9863, 9198, 3]\n",
      "分词结果： ['Hello', ',', 'world', '!', '你好', '，', '世界', '！']\n",
      "Encoded 输出: {'input_ids': [2, 14860, 18, 10298, 7, 13791, 9209, 9863, 9198, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "Input IDs: [2, 14860, 18, 10298, 7, 13791, 9209, 9863, 9198, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Attention Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# 输入文本\n",
    "text = \"Hello, world! 你好，世界！\"\n",
    "\n",
    "# 转换为token ID \n",
    "input_ids = tokenizer.encode(text)\n",
    "print(f\"Token ID:{input_ids}\")\n",
    "\n",
    "# 查看分词后的token\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(\"分词结果：\", tokens)\n",
    "\n",
    "encoded = tokenizer(\n",
    "    text,                   \n",
    "    # return_tensors=\"pt\",        # 返回 PyTorch 张量（\"tf\" 表示 TensorFlow，None 表示普通列表）\n",
    "    padding=\"max_length\",               # 自动填充（如果处理批量文本）\n",
    "    truncation=True,            # 自动截断（如果超过最大长度）\n",
    "    max_length=512              # 最大序列长度\n",
    ")\n",
    "\n",
    "print(\"Encoded 输出:\", encoded)\n",
    "\n",
    "# 提取 input_ids 和 attention_mask\n",
    "input_ids = encoded[\"input_ids\"]\n",
    "attention_mask = encoded[\"attention_mask\"]\n",
    "print(\"Input IDs:\", input_ids)\n",
    "print(\"Attention Mask:\", attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建Dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TranslationDataset(Dataset): \n",
    "    def __init__(self, dataset, tokenizer, max_length = 10):\n",
    "        self.dataset = dataset\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.pad_token_id = [self.tokenizer.convert_tokens_to_ids(self.tokenizer.pad_token)]\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        translation = self.dataset[index]['translation']\n",
    "        input = self.tokenizer(\n",
    "            translation[\"en\"],                   \n",
    "            # return_tensors=\"pt\",        # 返回 PyTorch 张量（\"tf\" 表示 TensorFlow，None 表示普通列表）\n",
    "            padding=\"max_length\",               # 自动填充（如果处理批量文本）\n",
    "            truncation=True,            # 自动截断（如果超过最大长度）\n",
    "            max_length=self.max_length              # 最大序列长度\n",
    "        )\n",
    "        output = self.tokenizer(\n",
    "            translation[\"zh\"],                   \n",
    "            # return_tensors=\"pt\",        # 返回 PyTorch 张量（\"tf\" 表示 TensorFlow，None 表示普通列表）\n",
    "            padding=\"max_length\",               # 自动填充（如果处理批量文本）\n",
    "            truncation=True,            # 自动截断（如果超过最大长度）\n",
    "            max_length=self.max_length              # 最大序列长度\n",
    "        )\n",
    "\n",
    "        # 提取 input_ids（去掉 batch 维度）\n",
    "        src_input = input[\"input_ids\"] # [seq_len]\n",
    "        src_attention_mask = input[\"attention_mask\"]\n",
    "        tgt_input = output[\"input_ids\"] # [seq_len] \n",
    "        tgt_output = tgt_input[1:] + self.pad_token_id # 去掉第一个 token（通常是 <BOS>）\n",
    "        \n",
    "        return [src_input, src_attention_mask, tgt_input, tgt_output]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_input, src_attention_mask, tgt_input, tgt_output = zip(*batch)\n",
    "    return (torch.tensor(src_input, dtype=torch.long)\n",
    "            , torch.tensor(src_attention_mask, dtype=torch.long).unsqueeze(1).unsqueeze(2)\n",
    "            , torch.tensor(tgt_input, dtype=torch.long)\n",
    "            , torch.tensor(tgt_output, dtype=torch.long))\n",
    "        \n",
    "train_dataset = TranslationDataset(dataset=dataset[\"train\"], tokenizer=tokenizer, max_length=10)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练模型\n",
    "\n",
    "vocab_size = tokenizer.vocab_size\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "d_ff = 2048\n",
    "num_layers = 6\n",
    "dropout = 0.1\n",
    "\n",
    "model = T5Model(vocab_size, d_model, num_heads, d_ff, num_layers, dropout)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer.convert_tokens_to_ids(tokenizer.pad_token))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76938496\n"
     ]
    }
   ],
   "source": [
    "param_num = [para.numel() for para in model.parameters()]\n",
    "sum = 0 \n",
    "for n in param_num:\n",
    "    sum += n\n",
    "    \n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 1, 10])\n",
      "torch.Size([256, 1, 1, 1, 1, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    2, 18129,  1701,  ...,  2480,  5911,     3],\n",
       "        [    2,  2060, 12497,  ...,  9574, 10031,     3],\n",
       "        [    2, 10464, 10264,  ...,  4038, 24211,     3],\n",
       "        ...,\n",
       "        [    2, 27628,    20,  ..., 11399, 12046,     3],\n",
       "        [    2,  7432, 10031,  ..., 11077,  7050,     3],\n",
       "        [    2, 17166,  2402,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(next(iter(train_loader))[1].shape)\n",
    "aa = next(iter(train_loader))[1].unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "print(aa.shape)\n",
    "\n",
    "\n",
    "tgt_test = next(iter(train_loader))[2]\n",
    "tgt_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ True, False, False,  ..., False, False, False],\n",
       "          [ True,  True, False,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          ...,\n",
       "          [ True,  True,  True,  ...,  True, False, False],\n",
       "          [ True,  True,  True,  ...,  True,  True, False],\n",
       "          [ True,  True,  True,  ...,  True,  True,  True]]],\n",
       "\n",
       "\n",
       "        [[[ True, False, False,  ..., False, False, False],\n",
       "          [ True,  True, False,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          ...,\n",
       "          [ True,  True,  True,  ...,  True, False, False],\n",
       "          [ True,  True,  True,  ...,  True,  True, False],\n",
       "          [ True,  True,  True,  ...,  True,  True,  True]]],\n",
       "\n",
       "\n",
       "        [[[ True, False, False,  ..., False, False, False],\n",
       "          [ True,  True, False,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          ...,\n",
       "          [ True,  True,  True,  ...,  True, False, False],\n",
       "          [ True,  True,  True,  ...,  True,  True, False],\n",
       "          [ True,  True,  True,  ...,  True,  True,  True]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ True, False, False,  ..., False, False, False],\n",
       "          [ True,  True, False,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          ...,\n",
       "          [ True,  True,  True,  ...,  True, False, False],\n",
       "          [ True,  True,  True,  ...,  True,  True, False],\n",
       "          [ True,  True,  True,  ...,  True,  True,  True]]],\n",
       "\n",
       "\n",
       "        [[[ True, False, False,  ..., False, False, False],\n",
       "          [ True,  True, False,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          ...,\n",
       "          [ True,  True,  True,  ...,  True, False, False],\n",
       "          [ True,  True,  True,  ...,  True,  True, False],\n",
       "          [ True,  True,  True,  ...,  True,  True,  True]]],\n",
       "\n",
       "\n",
       "        [[[ True, False, False,  ..., False, False, False],\n",
       "          [ True,  True, False,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          ...,\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False]]]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_mask(tgt, pad_idx): \n",
    "    tgt_seq_len = tgt.size(1)\n",
    "    tgt_mask = torch.tril(torch.ones((tgt_seq_len, tgt_seq_len))).bool().to(tgt.device)\n",
    "    tgt_mask = tgt_mask & (tgt != pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "    return tgt_mask \n",
    "\n",
    "pad_token_id = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "print(pad_token_id)\n",
    "\n",
    "test_size = tgt_test.shape[1]\n",
    "\n",
    "tgt_mask = torch.tril(torch.ones((test_size, test_size))).bool()\n",
    "tgt_mask = tgt_mask & (tgt_test != pad_token_id).unsqueeze(1).unsqueeze(2)\n",
    "print(test_size)\n",
    "tgt_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 252/3907 [00:47<11:32,  5.28it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[140], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     11\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 12\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_attention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_output\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrc_input\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msrc_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtgt_input\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtgt_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[135], line 15\u001b[0m, in \u001b[0;36mTranslationDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m---> 15\u001b[0m     translation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtranslation\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(\n\u001b[1;32m     17\u001b[0m         translation[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m],                   \n\u001b[1;32m     18\u001b[0m         \u001b[38;5;66;03m# return_tensors=\"pt\",        # 返回 PyTorch 张量（\"tf\" 表示 TensorFlow，None 表示普通列表）\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m         max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_length              \u001b[38;5;66;03m# 最大序列长度\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     )\n\u001b[1;32m     23\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(\n\u001b[1;32m     24\u001b[0m         translation[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzh\u001b[39m\u001b[38;5;124m\"\u001b[39m],                   \n\u001b[1;32m     25\u001b[0m         \u001b[38;5;66;03m# return_tensors=\"pt\",        # 返回 PyTorch 张量（\"tf\" 表示 TensorFlow，None 表示普通列表）\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m         max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_length              \u001b[38;5;66;03m# 最大序列长度\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/arrow_dataset.py:2777\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2776\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2777\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/arrow_dataset.py:2761\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2759\u001b[0m format_kwargs \u001b[38;5;241m=\u001b[39m format_kwargs \u001b[38;5;28;01mif\u001b[39;00m format_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m   2760\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[0;32m-> 2761\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m \u001b[43mquery_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2762\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m format_table(\n\u001b[1;32m   2763\u001b[0m     pa_subtable, key, formatter\u001b[38;5;241m=\u001b[39mformatter, format_columns\u001b[38;5;241m=\u001b[39mformat_columns, output_all_columns\u001b[38;5;241m=\u001b[39moutput_all_columns\n\u001b[1;32m   2764\u001b[0m )\n\u001b[1;32m   2765\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/formatting/formatting.py:615\u001b[0m, in \u001b[0;36mquery_table\u001b[0;34m(table, key, indices)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;66;03m# Query the main table\u001b[39;00m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 615\u001b[0m     pa_subtable \u001b[38;5;241m=\u001b[39m \u001b[43m_query_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    617\u001b[0m     pa_subtable \u001b[38;5;241m=\u001b[39m _query_table_with_indices_mapping(table, key, indices\u001b[38;5;241m=\u001b[39mindices)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/formatting/formatting.py:86\u001b[0m, in \u001b[0;36m_query_table\u001b[0;34m(table, key)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03mQuery a pyarrow Table to extract the subtable that correspond to the given key.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfast_slice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n\u001b[1;32m     88\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m*\u001b[39mkey\u001b[38;5;241m.\u001b[39mindices(table\u001b[38;5;241m.\u001b[39mnum_rows))\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/table.py:151\u001b[0m, in \u001b[0;36mIndexedTableMixin.fast_slice\u001b[0;34m(self, offset, length)\u001b[0m\n\u001b[1;32m    149\u001b[0m     batches[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m batches[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mslice(\u001b[38;5;241m0\u001b[39m, offset \u001b[38;5;241m+\u001b[39m length \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offsets[j])\n\u001b[1;32m    150\u001b[0m     batches[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m batches[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mslice(offset \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offsets[i])\n\u001b[0;32m--> 151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_batches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_schema\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "pad_token_id = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "num_epochs = 1\n",
    "use_flash_attn = False\n",
    "for epoch in range(num_epochs): \n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for (src_input, src_attention_mask, tgt_input, tgt_output) in tqdm(train_loader):\n",
    "        src_input = src_input.to(device)\n",
    "        tgt_input = tgt_input.to(device)\n",
    "        tgt_output = tgt_output.to(device)\n",
    "        src_attention_mask = src_attention_mask.to(device)\n",
    "        \n",
    "        tgt_mask = create_mask(tgt_input, pad_token_id)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        with autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "            logits = model(src_input, tgt_input, src_attention_mask, tgt_mask, use_flash_attn)    \n",
    "            loss = loss_fn(logits.view(-1, vocab_size), tgt_output.view(-1))\n",
    "        \n",
    "        scaler.scale(loss).backward()        \n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "                \n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f\"Epoch {epoch + 1} / {num_epochs}, Loss:{total_loss / len(train_loader)}\")\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(model, src_text, max_length=10000): \n",
    "    model.eval()\n",
    "    input = tokenizer(text=src_text, return_tensors=\"pt\")\n",
    "    src_input = input['input_ids'].to(device)\n",
    "    src_mask_attention = input['attention_mask'].to(device)\n",
    "    print(src_input)\n",
    "    print(src_mask_attention)\n",
    "\n",
    "    bos_id = tokenizer.bos_token_id\n",
    "    eos_id = tokenizer.eos_token_id\n",
    "\n",
    "    tgt_ids = [bos_id]\n",
    "    for _ in range(max_length):\n",
    "        tgt_input = torch.tensor([tgt_ids], dtype=torch.long).to(device)\n",
    "        # 使用falsh_attention模式，不需要mask\n",
    "        tgt_mask = torch.tril(torch.ones((len(tgt_ids), len(tgt_ids)))).bool().to(device)\n",
    "        tgt_mask = tgt_mask & (tgt_input != pad_token_id).unsqueeze(1).unsqueeze(2)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            with autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "                logits = model(src_input, tgt_input, src_mask_attention, use_flash_attn=True)\n",
    "            next_token = logits[0, -1].argmax().item()\n",
    "            \n",
    "        if next_token == eos_id:\n",
    "            break \n",
    "        \n",
    "        tgt_ids.append(next_token)\n",
    "        \n",
    "\n",
    "    return ''.join(tokenizer.convert_ids_to_tokens(tgt_ids)[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    2, 15363,  9359,  9674,     7,     3]], device='cuda:0')\n",
      "tensor([[1, 1, 1, 1, 1, 1]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "masked_fill() received an invalid combination of arguments - got (bool, float), but expected one of:\n * (Tensor mask, Tensor value)\n      didn't match because some of the arguments have invalid types: (!bool!, !float!)\n * (Tensor mask, Number value)\n      didn't match because some of the arguments have invalid types: (!bool!, !float!)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[142], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m src_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaybe you know!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m translated \u001b[38;5;241m=\u001b[39m \u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m翻译结果：\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtranslated\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[141], line 21\u001b[0m, in \u001b[0;36mtranslate\u001b[0;34m(model, src_text, max_length)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast(device_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16):\n\u001b[0;32m---> 21\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask_attention\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_flash_attn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     next_token \u001b[38;5;241m=\u001b[39m logits[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39margmax()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m next_token \u001b[38;5;241m==\u001b[39m eos_id:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[130], line 26\u001b[0m, in \u001b[0;36mT5Model.forward\u001b[0;34m(self, src_input, tgt_input, src_mask, tgt_mask, use_flash_attn)\u001b[0m\n\u001b[1;32m     24\u001b[0m dec_output \u001b[38;5;241m=\u001b[39m tgt_emb\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder_layers:\n\u001b[0;32m---> 26\u001b[0m     dec_output \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdec_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_flash_attn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer(dec_output)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[118], line 13\u001b[0m, in \u001b[0;36mDecoderLayer.forward\u001b[0;34m(self, x, enc_output, src_mask, tgt_mask, use_flash_attn)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, enc_output, src_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, tgt_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, use_flash_attn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m): \n\u001b[0;32m---> 13\u001b[0m      x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_flash_attn\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     14\u001b[0m      x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x), enc_output, enc_output, src_mask, use_flash_attn))\n\u001b[1;32m     15\u001b[0m      x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mff(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm3(x)))\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[114], line 52\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[0;34m(self, q, k, v, mask, use_flash_attn)\u001b[0m\n\u001b[1;32m     48\u001b[0m scores \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(q, k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)) \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_k)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# -1e9在半精度等训练时，会溢出，这里选择-1e4\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# scores = scores.masked_fill(mask==0, -1e9)\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mscores\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_fill\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1e4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m attention \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     54\u001b[0m output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(attention, v)\n",
      "\u001b[0;31mTypeError\u001b[0m: masked_fill() received an invalid combination of arguments - got (bool, float), but expected one of:\n * (Tensor mask, Tensor value)\n      didn't match because some of the arguments have invalid types: (!bool!, !float!)\n * (Tensor mask, Number value)\n      didn't match because some of the arguments have invalid types: (!bool!, !float!)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "src_text = \"maybe you know!\"\n",
    "\n",
    "translated = translate(model, src_text)\n",
    "\n",
    "print(f\"翻译结果：{translated}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
