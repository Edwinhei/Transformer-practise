{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 1000000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"opus100\", \"en-zh\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'translation': {'en': 'Sixty-first session', 'zh': '第六十一届会议'}}\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "\n",
    "class GPTEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 旋转位置编码\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "class RotaryEmbedding(nn.Module): \n",
    "    # 旋转位置编码实现\n",
    "    def __init__(self, dim: int, max_position: int = 10000): \n",
    "        super().__init__()\n",
    "        assert dim % 2 == 0, \"dim必须是偶数\"\n",
    "        self.dim = dim\n",
    "        self.max_position = max_position\n",
    "        \n",
    "        # 预计算频率\n",
    "        inv_freq = 1.0 / (10000 ** (torch.arange(0, dim, 2).float() / dim))\n",
    "        self.register_buffer(\"inv_freq\", inv_freq)\n",
    "        \n",
    "        # 预计算所有位置的cos和sin\n",
    "        self._precompute_embeddings()\n",
    "    \n",
    "    def _precompute_embeddings(self):\n",
    "        \"\"\"预计算最大长度的cos和sin\"\"\"\n",
    "        positions = torch.arange(self.max_position, dtype=torch.float)\n",
    "        freqs = positions[:, None] * self.inv_freq[None, :]  # (max_position, dim/2)\n",
    "        cos = torch.cos(freqs)\n",
    "        sin = torch.sin(freqs)\n",
    "        self.register_buffer(\"cos_cached\", cos, persistent=False)  # (max_position, dim/2)\n",
    "        self.register_buffer(\"sin_cached\", sin, persistent=False)\n",
    "    \n",
    "    def forward(self, seq_len: int, device: torch.device) -> tuple:\n",
    "        \"\"\"\n",
    "        在训练端，我们固定最大尺寸输入是ok的。因为我们为了训练，对传进来的序列长度对齐的。设定了最大长度规则，截断规则。\n",
    "        但是在预测段，最大固定尺寸max_position需要设置的大一些。大部分任务是单样本推理。此时，如果max_position设置过小，可能对生成结果有影响\n",
    "        我们，一般可以和对话最大字符度相同。或者略低。\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"根据序列长度返回对应的cos和sin\"\"\"\n",
    "        assert seq_len <= self.max_position, f\"seq_len ({seq_len}) 超过 max_position ({self.max_position})\"\n",
    "        \n",
    "        # 从缓存中截取需要的部分\n",
    "        cos = self.cos_cached[:seq_len].to(device)\n",
    "        sin = self.sin_cached[:seq_len].to(device)\n",
    "        return cos, sin\n",
    "    \n",
    "# 在单向or双向自注意力时可以这样操作。因为q，k同维度，当涉及交叉注意力时，此时就不能这么操作。\n",
    "def apply_rotary_emb(q: torch.Tensor, k: torch.Tensor, cos: torch.Tensor, sin: torch.Tensor) -> tuple:\n",
    "    \"\"\"应用旋转位置编码\"\"\"\n",
    "    cos = cos.unsqueeze(-2)  # 扩展维度为(seq_len, 1, d_k//2) 最后通过广播机制维度扩展(batch_size, seq_len, num_heads, d_k//2)\n",
    "    sin = sin.unsqueeze(-2)  # 扩展维度为(seq_len, 1, d_k//2) 最后通过广播机制维度扩展(batch_size, seq_len, num_heads, d_k//2)\n",
    "    q_ = q.float()\n",
    "    k_ = k.float()\n",
    "    trunc = q_.shape[-1]//2\n",
    "    q_rot = torch.cat([q_[..., :trunc] * cos - q_[..., trunc:] * sin,\n",
    "                      q_[..., :trunc] * sin + q_[..., trunc:] * cos], dim=-1)\n",
    "    k_rot = torch.cat([k_[..., :trunc] * cos - k_[..., trunc:] * sin,\n",
    "                      k_[..., :trunc] * sin + k_[..., trunc:] * cos], dim=-1)\n",
    "    return q_rot.type_as(q), k_rot.type_as(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class MultiHeadAttention(nn.Module): \n",
    "    def __init__(self, embed_dim, num_heads, max_position=10000, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads   \n",
    "        self.qkv_proj = nn.Linear(embed_dim, embed_dim * 3)    \n",
    "        self.out_linear = nn.Linear(embed_dim, embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.scale = torch.sqrt(torch.tensor(self.head_dim, dtype=torch.float))\n",
    "        \n",
    "        # 初始化旋转位置编码\n",
    "        self.rotary_emb = RotaryEmbedding(self.head_dim, max_position) \n",
    "        \n",
    "    # 这个注意力前向传播需要调整下，由于我们编解码类型，在交叉注意力计算时，由于q，k维度不一致。不能套用常规的ROPE编码\n",
    "    def forward(self, x, mask): \n",
    "        batch_size, seq_len, embed_dim = x.shape\n",
    "        \n",
    "        qkv = self.qkv_proj(x).view(batch_size, seq_len, 3, self.num_heads, self.head_dim)\n",
    "        q, k, v = qkv[:, :, 0], qkv[:, :, 1], qkv[:, :, 2] # (batch_size, seq_len, num_heads, head_dim)\n",
    "\n",
    "        # 生成旋转位置编码\n",
    "        cos, sin = self.rotary_emb(seq_len, q.device)\n",
    "\n",
    "        # q和k应用旋转位置编码\n",
    "        q, k = apply_rotary_emb(q, k, cos, sin)\n",
    "\n",
    "        q, k, v = q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2)\n",
    "        scores = torch.matmul(q, k.transpose(-1, -2)) / self.scale\n",
    "        \n",
    "        # mask包含因果掩码和attention_mask\n",
    "        scores = scores + mask.unsqueeze(1)\n",
    "        \n",
    "        weights = torch.softmax(scores, dim=-1)\n",
    "        \n",
    "        weights = self.dropout(weights)  # 在注意力权重上加 dropout\n",
    "        \n",
    "        output = torch.matmul(weights, v)\n",
    "        \n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, -1, embed_dim)\n",
    "        \n",
    "        return self.out_linear(output)\n",
    "    \n",
    "\n",
    "attn = MultiHeadAttention(512, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[786432, 1536, 262144, 512]\n",
      "1050624\n"
     ]
    }
   ],
   "source": [
    "params = [param.numel() for param in attn.parameters()]\n",
    "print(params)\n",
    "sum = 0\n",
    "for i in params:\n",
    "    sum += i \n",
    "print(sum)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1048576, 2048, 1048576, 512]\n",
      "2099712\n"
     ]
    }
   ],
   "source": [
    "class FeedForward(nn.Module): \n",
    "    def __init__(self, embed_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(embed_dim, embed_dim * 4)\n",
    "        self.fc2 = nn.Linear(embed_dim * 4, embed_dim)\n",
    "        self.gelu = nn.GELU()  # 使用 GELU 替换 ReLU\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x): \n",
    "        x = self.fc1(x)\n",
    "        x = self.gelu(x)  # 添加 GELU 激活\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)  # 在 FFN 输出上加 dropout\n",
    "        return x\n",
    "    \n",
    "ffn = FeedForward(512)\n",
    "param = [para.numel() for para in ffn.parameters()]\n",
    "print(param)\n",
    "sum = 0 \n",
    "for i in param:\n",
    "    sum += i\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[786432, 1536, 262144, 512, 1048576, 2048, 1048576, 512, 512, 512, 512, 512]\n",
      "3152384\n"
     ]
    }
   ],
   "source": [
    "class TransformerBlock(nn.Module): \n",
    "    def __init__(self, embed_dim, num_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadAttention(embed_dim, num_heads)\n",
    "        self.feed_forward = FeedForward(embed_dim)\n",
    "        self.norm1 = nn.LayerNorm(embed_dim) \n",
    "        self.norm2 = nn.LayerNorm(embed_dim) \n",
    "        self.dropout = nn.Dropout(dropout)  # 残差连接后的 dropout\n",
    "        \n",
    "    def forward(self, x, mask=None): \n",
    "        attn_output = self.attention(x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        \n",
    "        return x\n",
    "     \n",
    "transformerBlock = TransformerBlock(512, 8)\n",
    "\n",
    "params = [para.numel() for para in transformerBlock.parameters()]\n",
    "print(params)\n",
    "sum = 0\n",
    "for i in params:\n",
    "    sum += i\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf],\n",
       "        [0., 0., -inf],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.triu(torch.ones(size=(3, 3))*float('-inf'), diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., -inf, -inf, -inf],\n",
      "         [0., 0., -inf, -inf],\n",
      "         [0., 0., 0., -inf],\n",
      "         [0., 0., 0., 0.]]])\n",
      "tensor([[[0., -inf, -inf, -inf],\n",
      "         [0., 0., -inf, -inf],\n",
      "         [0., 0., 0., -inf],\n",
      "         [0., 0., 0., -inf]],\n",
      "\n",
      "        [[0., -inf, -inf, -inf],\n",
      "         [0., 0., -inf, -inf],\n",
      "         [0., 0., -inf, -inf],\n",
      "         [0., 0., -inf, -inf]]])\n"
     ]
    }
   ],
   "source": [
    "mask = torch.triu(torch.ones(size=(4, 4))*float('-inf'), diagonal=1)\n",
    "mask = mask.unsqueeze(0)\n",
    "print(mask)\n",
    "padding_mask = torch.tensor([[True, True, True, False],[True, True, False, False]])\n",
    "if padding_mask is not None: \n",
    "    padding_mask = padding_mask.unsqueeze(1)  # (batch_size, 1, seq_len)\n",
    "    mask = mask.masked_fill(~padding_mask, float('-inf'))\n",
    "    \n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding.embedding.weight ==> 参数量：24576000\n",
      "layers.0.attention.qkv_proj.weight ==> 参数量：1769472\n",
      "layers.0.attention.qkv_proj.bias ==> 参数量：2304\n",
      "layers.0.attention.out_linear.weight ==> 参数量：589824\n",
      "layers.0.attention.out_linear.bias ==> 参数量：768\n",
      "layers.0.feed_forward.fc1.weight ==> 参数量：2359296\n",
      "layers.0.feed_forward.fc1.bias ==> 参数量：3072\n",
      "layers.0.feed_forward.fc2.weight ==> 参数量：2359296\n",
      "layers.0.feed_forward.fc2.bias ==> 参数量：768\n",
      "layers.0.norm1.weight ==> 参数量：768\n",
      "layers.0.norm1.bias ==> 参数量：768\n",
      "layers.0.norm2.weight ==> 参数量：768\n",
      "layers.0.norm2.bias ==> 参数量：768\n",
      "layers.1.attention.qkv_proj.weight ==> 参数量：1769472\n",
      "layers.1.attention.qkv_proj.bias ==> 参数量：2304\n",
      "layers.1.attention.out_linear.weight ==> 参数量：589824\n",
      "layers.1.attention.out_linear.bias ==> 参数量：768\n",
      "layers.1.feed_forward.fc1.weight ==> 参数量：2359296\n",
      "layers.1.feed_forward.fc1.bias ==> 参数量：3072\n",
      "layers.1.feed_forward.fc2.weight ==> 参数量：2359296\n",
      "layers.1.feed_forward.fc2.bias ==> 参数量：768\n",
      "layers.1.norm1.weight ==> 参数量：768\n",
      "layers.1.norm1.bias ==> 参数量：768\n",
      "layers.1.norm2.weight ==> 参数量：768\n",
      "layers.1.norm2.bias ==> 参数量：768\n",
      "layers.2.attention.qkv_proj.weight ==> 参数量：1769472\n",
      "layers.2.attention.qkv_proj.bias ==> 参数量：2304\n",
      "layers.2.attention.out_linear.weight ==> 参数量：589824\n",
      "layers.2.attention.out_linear.bias ==> 参数量：768\n",
      "layers.2.feed_forward.fc1.weight ==> 参数量：2359296\n",
      "layers.2.feed_forward.fc1.bias ==> 参数量：3072\n",
      "layers.2.feed_forward.fc2.weight ==> 参数量：2359296\n",
      "layers.2.feed_forward.fc2.bias ==> 参数量：768\n",
      "layers.2.norm1.weight ==> 参数量：768\n",
      "layers.2.norm1.bias ==> 参数量：768\n",
      "layers.2.norm2.weight ==> 参数量：768\n",
      "layers.2.norm2.bias ==> 参数量：768\n",
      "layers.3.attention.qkv_proj.weight ==> 参数量：1769472\n",
      "layers.3.attention.qkv_proj.bias ==> 参数量：2304\n",
      "layers.3.attention.out_linear.weight ==> 参数量：589824\n",
      "layers.3.attention.out_linear.bias ==> 参数量：768\n",
      "layers.3.feed_forward.fc1.weight ==> 参数量：2359296\n",
      "layers.3.feed_forward.fc1.bias ==> 参数量：3072\n",
      "layers.3.feed_forward.fc2.weight ==> 参数量：2359296\n",
      "layers.3.feed_forward.fc2.bias ==> 参数量：768\n",
      "layers.3.norm1.weight ==> 参数量：768\n",
      "layers.3.norm1.bias ==> 参数量：768\n",
      "layers.3.norm2.weight ==> 参数量：768\n",
      "layers.3.norm2.bias ==> 参数量：768\n",
      "layers.4.attention.qkv_proj.weight ==> 参数量：1769472\n",
      "layers.4.attention.qkv_proj.bias ==> 参数量：2304\n",
      "layers.4.attention.out_linear.weight ==> 参数量：589824\n",
      "layers.4.attention.out_linear.bias ==> 参数量：768\n",
      "layers.4.feed_forward.fc1.weight ==> 参数量：2359296\n",
      "layers.4.feed_forward.fc1.bias ==> 参数量：3072\n",
      "layers.4.feed_forward.fc2.weight ==> 参数量：2359296\n",
      "layers.4.feed_forward.fc2.bias ==> 参数量：768\n",
      "layers.4.norm1.weight ==> 参数量：768\n",
      "layers.4.norm1.bias ==> 参数量：768\n",
      "layers.4.norm2.weight ==> 参数量：768\n",
      "layers.4.norm2.bias ==> 参数量：768\n",
      "layers.5.attention.qkv_proj.weight ==> 参数量：1769472\n",
      "layers.5.attention.qkv_proj.bias ==> 参数量：2304\n",
      "layers.5.attention.out_linear.weight ==> 参数量：589824\n",
      "layers.5.attention.out_linear.bias ==> 参数量：768\n",
      "layers.5.feed_forward.fc1.weight ==> 参数量：2359296\n",
      "layers.5.feed_forward.fc1.bias ==> 参数量：3072\n",
      "layers.5.feed_forward.fc2.weight ==> 参数量：2359296\n",
      "layers.5.feed_forward.fc2.bias ==> 参数量：768\n",
      "layers.5.norm1.weight ==> 参数量：768\n",
      "layers.5.norm1.bias ==> 参数量：768\n",
      "layers.5.norm2.weight ==> 参数量：768\n",
      "layers.5.norm2.bias ==> 参数量：768\n",
      "output_layer.weight ==> 参数量：24576000\n",
      "output_layer.bias ==> 参数量：32000\n",
      "91711232\n"
     ]
    }
   ],
   "source": [
    "# 组合GPT模型\n",
    "class GPT(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_layers, num_heads):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 词嵌入层\n",
    "        self.embedding = GPTEmbedding(vocab_size, embed_dim)      \n",
    "        \n",
    "        # Transformer blocks\n",
    "        self.layers = nn.ModuleList([TransformerBlock(embed_dim, num_heads) for _ in range(num_layers)])\n",
    "        \n",
    "        # 输出头\n",
    "        self.output_layer = nn.Linear(embed_dim, vocab_size)\n",
    "    \n",
    "    def forward(self, token_ids, padding_mask=None): \n",
    "        batch_size, seq_len = token_ids.shape\n",
    "        x = self.embedding(token_ids)\n",
    "        \n",
    "        mask = torch.triu(torch.ones(size=(seq_len, seq_len))*float('-inf'), diagonal=1)\n",
    "        mask = mask.unsqueeze(0).to(token_ids.device)\n",
    "        \n",
    "        if padding_mask is not None: \n",
    "            padding_mask = padding_mask.unsqueeze(1)  # (batch_size, 1, seq_len)\n",
    "            mask = mask.masked_fill(~padding_mask, float('-inf'))\n",
    "            \n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "\n",
    "        logits = self.output_layer(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "gpt = GPT(32000, 768, 6, 8)\n",
    "\n",
    "sum = 0 \n",
    "\n",
    "for name,param in gpt.named_parameters(): \n",
    "    print(f\"{name} ==> 参数量：{param.numel()}\")\n",
    "    sum += param.numel()\n",
    "    \n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 生成词汇表\n",
    "# from generate_tokenizer import gen_tokenizer\n",
    "\n",
    "# # 传入语料库文件， 输出tokenizer的json文件\n",
    "# src_path = \"corpus.txt\"\n",
    "# tokenizer_path = \"translation.json\"\n",
    "# gen_tokenizer(src_path, tokenizer_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad token: [PAD]\n",
      "特殊 token 映射： {'bos_token': '[BOS]', 'eos_token': '[EOS]', 'unk_token': '[UNK]', 'pad_token': '[PAD]'}\n",
      "Pad token ID: 0\n",
      "BOS token ID: 2\n",
      "BOS token ID: 2\n",
      "EOS token ID: 3\n",
      "PAD token ID: 0\n",
      "EOS token ID: 3\n"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "# 加载 tokenizer，显式设置特殊 token\n",
    "tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_file=\"translation.json\",\n",
    "    pad_token=\"[PAD]\",\n",
    "    unk_token=\"[UNK]\",\n",
    "    bos_token=\"[BOS]\",\n",
    "    eos_token=\"[EOS]\"\n",
    ")\n",
    "\n",
    "# 打印特殊 token 和映射\n",
    "print(\"Pad token:\", tokenizer.pad_token)\n",
    "print(\"特殊 token 映射：\", tokenizer.special_tokens_map)\n",
    "print(\"Pad token ID:\", tokenizer.pad_token_id)\n",
    "print(\"BOS token ID:\", tokenizer.convert_tokens_to_ids(\"[BOS]\"))\n",
    "print(\"BOS token ID:\", tokenizer.convert_tokens_to_ids(\"[BOS]\"))\n",
    "print(\"EOS token ID:\", tokenizer.convert_tokens_to_ids(\"[EOS]\"))\n",
    "print(\"PAD token ID:\", tokenizer.convert_tokens_to_ids(\"[PAD]\"))\n",
    "print(\"EOS token ID:\", tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token ID: [2, 14860, 18, 10298, 7, 13791, 9209, 9863, 9198, 3]\n",
      "分词结果： ['Hello', ',', 'world', '!', '你好', '，', '世界', '！']\n",
      "Encoded 输出: {'input_ids': tensor([[    2, 14860,    18, 10298,     7, 13791,  9209,  9863,  9198,     3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Input IDs: tensor([[    2, 14860,    18, 10298,     7, 13791,  9209,  9863,  9198,     3]])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "带特殊 token 的分词结果： ['[BOS]', 'Hello', ',', 'world', '!', '你好', '，', '世界', '！', '[EOS]']\n"
     ]
    }
   ],
   "source": [
    "# 输入文本\n",
    "text = \"Hello, world! 你好，世界！\"\n",
    "\n",
    "# 转换为 token ID\n",
    "input_ids = tokenizer.encode(text)\n",
    "print(f\"Token ID: {input_ids}\")\n",
    "\n",
    "# 查看分词后的 token\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(\"分词结果：\", tokens)\n",
    "\n",
    "encoded = tokenizer(\n",
    "    text,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512\n",
    ")\n",
    "print(\"Encoded 输出:\", encoded)\n",
    "\n",
    "# 提取 input_ids 和 attention_mask\n",
    "input_ids = encoded[\"input_ids\"]\n",
    "attention_mask = encoded[\"attention_mask\"]\n",
    "print(\"Input IDs:\", input_ids)\n",
    "print(\"Attention Mask:\", attention_mask)\n",
    "\n",
    "# 转换为 token 查看\n",
    "tokens_with_special = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "print(\"带特殊 token 的分词结果：\", tokens_with_special)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token ID:[2, 14860, 18, 10298, 7, 13791, 9209, 9863, 9198, 3]\n",
      "分词结果： ['Hello', ',', 'world', '!', '你好', '，', '世界', '！']\n",
      "Encoded 输出: {'input_ids': [2, 14860, 18, 10298, 7, 13791, 9209, 9863, 9198, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "Input IDs: [2, 14860, 18, 10298, 7, 13791, 9209, 9863, 9198, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Attention Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# 输入文本\n",
    "text = \"Hello, world! 你好，世界！\"\n",
    "\n",
    "# 转换为token ID \n",
    "input_ids = tokenizer.encode(text)\n",
    "print(f\"Token ID:{input_ids}\")\n",
    "\n",
    "# 查看分词后的token\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(\"分词结果：\", tokens)\n",
    "\n",
    "encoded = tokenizer(\n",
    "    text,                   \n",
    "    # return_tensors=\"pt\",        # 返回 PyTorch 张量（\"tf\" 表示 TensorFlow，None 表示普通列表）\n",
    "    padding=\"max_length\",               # 自动填充（如果处理批量文本）\n",
    "    truncation=True,            # 自动截断（如果超过最大长度）\n",
    "    max_length=512              # 最大序列长度\n",
    ")\n",
    "\n",
    "print(\"Encoded 输出:\", encoded)\n",
    "\n",
    "# 提取 input_ids 和 attention_mask\n",
    "input_ids = encoded[\"input_ids\"]\n",
    "attention_mask = encoded[\"attention_mask\"]\n",
    "print(\"Input IDs:\", input_ids)\n",
    "print(\"Attention Mask:\", attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token ID:[7036, 1678, 22447, 30075, 19849, 1031, 9223]\n"
     ]
    }
   ],
   "source": [
    "# 输入文本\n",
    "text = \"该句子的中文翻译为：\"\n",
    "\n",
    "# 转换为token ID \n",
    "input_ids = tokenizer.encode(text)[1:-1]\n",
    "print(f\"Token ID:{input_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 9553, 13, 89, 71, 14306, 20, 11351, 9313, 27651, 9359, 20, 9617, 13, 89, 16990, 9359, 71, 9371, 18425, 20, 7036, 1678, 22447, 30075, 19849, 1031, 9223, 14481, 2060, 11186, 1180, 9209, 13750, 11540, 26767, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"该句子的中文翻译为：\"\n",
    "text = dataset[\"train\"][2]['translation'][\"en\"]+text+dataset[\"train\"][2]['translation'][\"zh\"]\n",
    "\n",
    "input = tokenizer(\n",
    "            text,                   \n",
    "            # return_tensors=\"pt\",        # 返回 PyTorch 张量（\"tf\" 表示 TensorFlow，None 表示普通列表）\n",
    "            padding=\"max_length\",               # 自动填充（如果处理批量文本）\n",
    "            truncation=True,            # 自动截断（如果超过最大长度）\n",
    "            max_length=100              # 最大序列长度\n",
    "        )\n",
    "\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建Dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TranslationDataset(Dataset): \n",
    "    def __init__(self, dataset, tokenizer, default_text, max_length = 100):\n",
    "        self.default_text = default_text\n",
    "        self.dataset = dataset\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.pad_token_id = [self.tokenizer.pad_token_id]\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        translation = self.dataset[index]['translation']\n",
    "        text = translation[\"en\"] + self.default_text + translation[\"zh\"]\n",
    "        input = self.tokenizer(\n",
    "            text,                   \n",
    "            padding=\"max_length\",               # 自动填充（如果处理批量文本）\n",
    "            truncation=True,            # 自动截断（如果超过最大长度）\n",
    "            max_length=self.max_length              # 最大序列长度\n",
    "        )\n",
    "        \n",
    "        # 提取 input_ids（去掉 batch 维度）\n",
    "        input_ids = input[\"input_ids\"] # [seq_len]\n",
    "        attention_mask = input[\"attention_mask\"]\n",
    "        label = input_ids[1:] + self.pad_token_id # 去掉第一个 token（ <BOS>）\n",
    "        \n",
    "        return [input_ids, attention_mask, label]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids, attention_masks, labels = zip(*batch)\n",
    "    return (torch.tensor(input_ids, dtype=torch.long)\n",
    "            , torch.tensor(attention_masks, dtype=torch.bool)\n",
    "            , torch.tensor(labels, dtype=torch.long))\n",
    "        \n",
    "train_dataset = TranslationDataset(dataset=dataset[\"train\"], tokenizer=tokenizer, default_text=\"该句子的中文翻译为：\", max_length=100)\n",
    "train_loader = DataLoader(train_dataset, batch_size=48, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48, 100])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练模型\n",
    "\n",
    "vocab_size = tokenizer.vocab_size\n",
    "embed_dim = 512\n",
    "num_heads = 8\n",
    "d_ff = 2048\n",
    "num_layers = 6\n",
    "dropout = 0.1\n",
    "\n",
    "model = GPT(vocab_size, embed_dim, num_layers, num_heads)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51714304\n"
     ]
    }
   ],
   "source": [
    "param_num = [para.numel() for para in model.parameters()]\n",
    "sum = 0 \n",
    "for n in param_num:\n",
    "    sum += n\n",
    "    \n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48, 100])\n",
      "torch.Size([48, 1, 1, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[10037,  9313,  9356,  ...,     0,     0,     0],\n",
       "        [ 9604, 13419, 20922,  ...,     0,     0,     0],\n",
       "        [10089,  9468,  9709,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [   47, 10340, 10236,  ...,     0,     0,     0],\n",
       "        [14423,    18,  9320,  ...,  1425,     3,     0],\n",
       "        [   47,    13,    83,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(next(iter(train_loader))[1].shape)\n",
    "aa = next(iter(train_loader))[1].unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "print(aa.shape)\n",
    "\n",
    "\n",
    "tgt_test = next(iter(train_loader))[2]\n",
    "tgt_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4553/20834 [07:48<27:56,  9.71it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(logits\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, vocab_size), labels\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     23\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 24\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m     27\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/amp/grad_scaler.py:457\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    455\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 457\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/amp/grad_scaler.py:351\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    345\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    350\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    352\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/torch/amp/grad_scaler.py:351\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    345\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    350\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    352\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "pad_token_id = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs): \n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for (input_ids, attention_masks, labels) in tqdm(train_loader):\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_masks = attention_masks.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "            logits = model(input_ids, attention_masks)\n",
    "            loss = loss_fn(logits.view(-1, vocab_size), labels.view(-1))\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "                \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f\"Epoch {epoch + 1} / {num_epochs}, Loss:{total_loss / len(train_loader)}\")\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(model, src_text, max_length=10000):\n",
    "    model.eval()\n",
    "    input = tokenizer(text=src_text)[\"input_ids\"][:-1]\n",
    "    eos_id = tokenizer.eos_token_id\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        with torch.no_grad():\n",
    "            with autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "                logits = model(torch.tensor([input], dtype=torch.long).to(device))\n",
    "            next_token = logits[0, -1].argmax().item()\n",
    "        if next_token == eos_id:\n",
    "            break\n",
    "        input.append(next_token)\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input)[1:]\n",
    "    output = \"\"\n",
    "    for i, token in enumerate(tokens):\n",
    "        # 清洗BPE空格符并分类字符\n",
    "        clean_token = token.replace('▁', '')\n",
    "        is_chinese = all(0x4E00 <= ord(c) <= 0x9FFF for c in clean_token)\n",
    "        is_eng_punct = clean_token in {\".\", \",\", \"!\", \"?\", \":\"}  # 英文标点\n",
    "        is_cn_punct = clean_token in {\"，\", \"。\", \"！\", \"？\", \"：\"}  # 中文标点\n",
    "        \n",
    "        # 空格判断逻辑\n",
    "        space_needed = False\n",
    "        if i > 0:\n",
    "            prev_clean = tokens[i-1].replace('▁', '')\n",
    "            prev_eng_punct = prev_clean in {\".\", \",\", \"!\", \"?\", \":\"}\n",
    "            prev_cn_punct = prev_clean in {\"，\", \"。\", \"！\", \"？\", \"：\"}\n",
    "            \n",
    "            # 英文标点后需要空格的条件\n",
    "            if prev_eng_punct and not (is_chinese or is_cn_punct):\n",
    "                space_needed = True\n",
    "            # 连续英文非标点需要空格\n",
    "            elif not (is_chinese or is_eng_punct or is_cn_punct) and \\\n",
    "                 not (prev_cn_punct or prev_eng_punct or prev_clean == \"\"):\n",
    "                space_needed = True\n",
    "        \n",
    "        output += (\" \" if space_needed else \"\") + clean_token\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "翻译结果：Hello? I ' m here.该句子的中文翻译为：-哦，我\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "src_text = \"Hello? I'm here\" \n",
    "\n",
    "translated = translate(model, src_text)\n",
    "\n",
    "print(f\"翻译结果：{translated}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
